{
    "componentChunkName": "component---gatsby-theme-academic-src-templates-post-post-jsx",
    "path": "/research/mmtutor",
    "result": {"data":{"mdx":{"timeToRead":1,"tableOfContents":{"items":[{"url":"#introduction","title":"Introduction"},{"url":"#framework","title":"Framework"},{"url":"#fundamentals","title":"Fundamentals","items":[{"url":"#aruco-marker","title":"ArUco Marker"},{"url":"#mediapipe-hand","title":"MediaPipe Hand"},{"url":"#presentation","title":"Presentation"}]}]},"frontmatter":{"cover":{"childImageSharp":{"fluid":{"tracedSVG":"data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20width='320'%20height='180'%20viewBox='0%200%20320%20180'%20preserveAspectRatio='none'%3e%3cpath%20d='M273%201c-6%200-6%200-6%203s0%203%203%203%203%200%203%206c0%205%200%205%203%205h3V9l1-8h-7m32%202c-2%201-5%206-7%2010-4%206-4%207-2%207%201%200%202%201%202%203%200%203%200%203-3%203s-3%200-3%203c0%202%200%202%203%202s3%200%203%204v3h-8c-5%200-8%200-7%201%202%201-5%206-8%206-7%200-7%200-7%206%200%205-1%206-3%206-3%200-4-1-4-4s0-3-5-2l-4-1h-2l-1-1c1-1%200-1-1-2-2%200-3-2-3-3l-3-2h-3c-1-1-3-2-4-1l-2-1-3-2-1-1-9-2-2-2-4-1h-4l-4-1-14-3-5-1c-2%201-3%201-4-1l-2-1h-10l-2%202-3%201-2%202-3%201-1%201c1%203-5%202-7-1-2-4-4-15-3-16l11-1c13-1%2018-3%207-3l-9-1h-3l-3-2-1-1-1-2c-1-1-1-1%201-2%205-2-93-1-139%202H0v11h7l73-1-2%2010-2%209H48c-22%201-29%200-34-1-7-1-7-1-9%201l-3%202c-2%200-2%201-2%2015v16l4%201c12%203%2030%206%2033%205h4l-5-1c-5-1-4-3%201-3h4l-4-2-3-2%208%201%2015%201%2015%202c6%200%209%201%2010%202l-18%201H46l17%201c18%200%2019%200%2019%204%200%201-3%202-21%201H40l5%205%2010%209%205%204-13-8c-2-2-11-6-16-6a1264%201264%200%2000-17-3l-4-1-6-2H0v104h321V94l-1-90V0h-6c-6%200-7%200-9%203M81%2017l-2%2010-2%207h4l6-1c1-2%204-2%2011-2l10-1%2017-1%2016-1c0-2-4-3-7-3-5%200-13%200-11-1%202%200%202-1%202-5%200-2%200-4-1-3l-1-1-20-1H82l-1%203m219%209v6h3c3%200%203%200%203%203-1%202-1%202%205%202s6%200%206-2c0-3%200-3-3-3s-3%200-3-3%200-3-3-3c-2%200-3%200-3-3%200-2%200-3-2-3-3%200-3%200-3%206m-57%208l-1%203%209%201h10v-6h-9c-8%200-9%200-9%202M123%2050v9l1%207h7l8-1V48h-8c-6%200-7%200-8%202m22-1c-2%200-2%204-1%2013l1%205%205-1%207-1h3v-8l-1-8h-14m-41%201l-2%201-1%203%202%208v5h15V52l-5-1-5-1h-4m26%2021h-4l-2%201c-1%200-1%2014%201%2015h15v-6l-1-8-3-1c-3%200-4-1-5-2s-1-1-1%201m-26%200l-2%202-1%203v3l2%205c1%205%202%206%2011%205%206-1%206-2%204-12v-5h-5l-4-1h-5m42%200c-2%200-2%201-2%205l1%209v3h15V71h-14m-20%209v5h5c6%200%207-2%206-8-1-4-5-4-5%200v4l-1-4c-2-6-5-4-5%203m1%2011l-1%201c-2%201-2%202-2%207%200%207%200%208%208%208%208%201%208%201%207-8v-6h-4l-5-2-2-1-1%201m20%200l-2%201-1%208%201%208%208-1h7V93l-5-1-5-1-1-1-2%201m-40%201c-2%202-2%206-1%2012v4h15v-4c0-8-1-11-3-11-6-2-10-2-11-1m68%2013c-6%202-10%205-9%208l-1%202h-1l1%202%201-1%202%201%203%202-1-2v-1c1%201%203%200%205-1l5-1%204%201%2010-2%201-3%201-4c0-2-12-2-21-1m109%2028l-6%202c-2%201%200%206%202%207%203%202%2015%205%2015%204%201-1-4-14-5-14l-6%201'%20fill='%23d3d3d3'%20fill-rule='evenodd'/%3e%3c/svg%3e","aspectRatio":1.7857142857142858,"src":"/static/33e3d595276bd9d1a8c431dbe54202e2/31987/preview.png","srcSet":"/static/33e3d595276bd9d1a8c431dbe54202e2/e1953/preview.png 250w,\n/static/33e3d595276bd9d1a8c431dbe54202e2/46604/preview.png 500w,\n/static/33e3d595276bd9d1a8c431dbe54202e2/31987/preview.png 1000w,\n/static/33e3d595276bd9d1a8c431dbe54202e2/0dadc/preview.png 1500w,\n/static/33e3d595276bd9d1a8c431dbe54202e2/0a640/preview.png 1724w","sizes":"(max-width: 1000px) 100vw, 1000px"}}}},"fileAbsolutePath":"/home/runner/work/henrw.github.io/henrw.github.io/example/content/research/mmtutor/index.md","fields":{"slug":{"html":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Multimodal Cognitive Tutor\",\n  \"tags\": [\"IntelligentTutoringSystem\", \"XR\", \"HCI\"],\n  \"date\": \"May 2022 - Present\",\n  \"path\": \"research/mmtutor\",\n  \"excerpt\": \"A new ITS framework generalizable for 3D physical task learning. By leveraging AI and AR methods, it can not only generate adaptive guidance by modeling users’ learning stage and measuring difficulties of learning objects through multimodal input, but also preserve perspectives of reality for users with spatially augmented animations that reduce users’ cognitive load.\",\n  \"selected\": true,\n  \"cover\": \"./preview.png\",\n  \"links\": [{\n    \"name\": \"poster\",\n    \"url\": \"poster.pdf\"\n  }, {\n    \"name\": \"Github\",\n    \"url\": \"https://github.com/HumanAILab/Multimodal-Tutor\"\n  }],\n  \"priority\": 1\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"Advisors: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://web.eecs.umich.edu/~xwanghci/\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow\"\n  }, \"Prof. Xu Wang\"), \" and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://guoanhong.com/\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow\"\n  }, \"Prof. Anhong Guo\")), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"This is an ongoing project about the broad topic of the intelligent tutoring system (ITS) and there have been many interesting ideas popping up. Please stay tuned for updates.\")), mdx(\"h2\", {\n    \"id\": \"introduction\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h2\",\n    \"aria-hidden\": \"true\",\n    \"tabIndex\": -1,\n    \"href\": \"#introduction\"\n  }, mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"icon icon-link\"\n  })), mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#introduction\",\n    \"aria-label\": \"introduction permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Introduction\"), mdx(\"p\", null, \"Traditionally, self-learning of 3D physical tasks (e.g. playing basketball, assembly, etc.) relies on 2D static instructions, e.g. manuals and instruction videos, which\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Lack instant feedback / dynamic task generation\\nfor knowledge enhancement\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Have high cognitive load for hidden information\")), mdx(\"p\", null, \"The ITS is a potential approach to them. Nevertheless, challenges exist in\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Capturing learners\\u2019 behaviors in 3D space\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Preserving learning space & reality similarity\")), mdx(\"p\", null, \"Consequently, we need a new ITS framework that copes with these issues...\"), mdx(\"h2\", {\n    \"id\": \"framework\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h2\",\n    \"aria-hidden\": \"true\",\n    \"tabIndex\": -1,\n    \"href\": \"#framework\"\n  }, mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"icon icon-link\"\n  })), mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#framework\",\n    \"aria-label\": \"framework permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Framework\"), mdx(\"p\", null, \"Here we provide the high-level diagram of our ITS framework. More design considerations will be disclosed.\\n\", mdx(\"img\", {\n    parentName: \"p\",\n    \"src\": \"/files/a5bd6a2732ffb7674d241c6cd188bf63/tutor.png\",\n    \"alt\": \"Tutor framework\"\n  })), mdx(\"p\", null, \"We specifically create the instance for the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Rubik%27s_Cube\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow\"\n  }, \"Rubik's Cube\"), \". Here is a quick demo picture.\\n\", mdx(\"img\", {\n    parentName: \"p\",\n    \"src\": \"/files/2a920893747da9ffa5d43b1c2746baa2/demo.png\",\n    \"alt\": \"Demo origin\"\n  })), mdx(\"h2\", {\n    \"id\": \"fundamentals\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h2\",\n    \"aria-hidden\": \"true\",\n    \"tabIndex\": -1,\n    \"href\": \"#fundamentals\"\n  }, mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"icon icon-link\"\n  })), mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#fundamentals\",\n    \"aria-label\": \"fundamentals permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Fundamentals\"), mdx(\"h3\", {\n    \"id\": \"aruco-marker\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"aria-hidden\": \"true\",\n    \"tabIndex\": -1,\n    \"href\": \"#aruco-marker\"\n  }, mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"icon icon-link\"\n  })), mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#aruco-marker\",\n    \"aria-label\": \"aruco marker permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"ArUco Marker\"), mdx(\"p\", null, \"ArUco Markers are really popular in XR applications. We applied them as they provide higher detection accuracy facilitating domain modeling (robust in different environments for their high contrast) and bigger design space for user feedback.\"), mdx(\"p\", null, \"Please refer to \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://docs.opencv.org/4.x/d5/dae/tutorial_aruco_detection.html\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow\"\n  }, \"OpenCV library\"), \" for their usage.\"), mdx(\"p\", null, mdx(\"img\", {\n    parentName: \"p\",\n    \"src\": \"/files/c0532c4efc0492a41933c28a03255dfd/markers.jpg\",\n    \"alt\": \"ArUco Markers\"\n  })), mdx(\"h3\", {\n    \"id\": \"mediapipe-hand\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"aria-hidden\": \"true\",\n    \"tabIndex\": -1,\n    \"href\": \"#mediapipe-hand\"\n  }, mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"icon icon-link\"\n  })), mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#mediapipe-hand\",\n    \"aria-label\": \"mediapipe hand permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"MediaPipe Hand\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://google.github.io/mediapipe/\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow\"\n  }, \"MediaPipe\"), \" offers cross-platform, customizable ML solutions for live and streaming media.\")), mdx(\"p\", null, \"In our system, we applied MediaPipe \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://google.github.io/mediapipe/solutions/hands.html\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow\"\n  }, \"Hand\"), \" for finger detection, facilitating user modeling.\"), mdx(\"p\", null, mdx(\"img\", {\n    parentName: \"p\",\n    \"src\": \"/files/27f125772eaba3e9aa4394fccfa62b2b/finger.png\",\n    \"alt\": \"Finger Detection\"\n  })), mdx(\"h3\", {\n    \"id\": \"presentation\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"aria-hidden\": \"true\",\n    \"tabIndex\": -1,\n    \"href\": \"#presentation\"\n  }, mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"icon icon-link\"\n  })), mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#presentation\",\n    \"aria-label\": \"presentation permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Presentation\"), mdx(\"p\", null, \"We presented our work at \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"../posts/mi-ai-symposium-2022\"\n  }, \"Michigan AI Symposium 2022\"), \" and won the Best Demo Award.\"));\n}\n;\nMDXContent.isMDXComponent = true;","htmlEncrypted":"","nonce":"","title":"Multimodal Cognitive Tutor","date":"May 2022 - Present","tags":["IntelligentTutoringSystem","XR","HCI"],"path":"research/mmtutor","excerpt":"A new ITS framework generalizable for 3D physical task learning. By leveraging AI and AR methods, it can not only generate adaptive guidance by modeling users’ learning stage and measuring difficulties of learning objects through multimodal input, but also preserve perspectives of reality for users with spatially augmented animations that reduce users’ cognitive load.","links":[{"name":"poster"},{"name":"Github"}],"commit":1672250238,"type":"research"}}}},"pageContext":{"fileAbsolutePath":"/home/runner/work/henrw.github.io/henrw.github.io/example/content/research/mmtutor/index.md","postPath":"research/mmtutor","translations":[{"hreflang":"en","path":"/research/mmtutor"}]}},
    "staticQueryHashes": ["1552981879","3833539658","4097791827"]}