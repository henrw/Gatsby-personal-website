{"data":{"allTag":{"edges":[{"node":{"name":"IntelligentTutoringSystem","color":"lime","path":"/tags/IntelligentTutoringSystem"}},{"node":{"name":"XR","color":"blue","path":"/tags/XR"}},{"node":{"name":"HCI","color":"gold","path":"/tags/HCI"}},{"node":{"name":"MisinformationDetection","color":"lime","path":"/tags/MisinformationDetection"}},{"node":{"name":"MultimodalLearning","color":"green","path":"/tags/MultimodalLearning"}},{"node":{"name":"NLP","color":"magenta","path":"/tags/NLP"}},{"node":{"name":"GeneralistAgent","color":"gold","path":"/tags/GeneralistAgent"}},{"node":{"name":"Simulation","color":"magenta","path":"/tags/Simulation"}},{"node":{"name":"RL","color":"red","path":"/tags/RL"}},{"node":{"name":"AbstractiveTextSummary","color":"volcano","path":"/tags/AbstractiveTextSummary"}},{"node":{"name":"GAN","color":"orange","path":"/tags/GAN"}},{"node":{"name":"SpuriousCorrelation","color":"blue","path":"/tags/SpuriousCorrelation"}},{"node":{"name":"DeepLearning","color":"volcano","path":"/tags/DeepLearning"}},{"node":{"name":"AI","color":"red","path":"/tags/AI"}},{"node":{"name":"PokemonGold","color":"cyan","path":"/tags/PokemonGold"}},{"node":{"name":"Modeling","color":"green","path":"/tags/Modeling"}},{"node":{"name":"OpenGL","color":"cyan","path":"/tags/OpenGL"}},{"node":{"name":"Gatsby","color":"orange","path":"/tags/Gatsby"}},{"node":{"name":"gatsby","color":"geekblue","path":"/tags/gatsby"}}]},"allMdx":{"edges":[{"node":{"frontmatter":{"cover":{"childImageSharp":{"fluid":{"tracedSVG":"data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20width='320'%20height='180'%20viewBox='0%200%20320%20180'%20preserveAspectRatio='none'%3e%3cpath%20d='M273%201c-6%200-6%200-6%203s0%203%203%203%203%200%203%206c0%205%200%205%203%205h3V9l1-8h-7m32%202c-2%201-5%206-7%2010-4%206-4%207-2%207%201%200%202%201%202%203%200%203%200%203-3%203s-3%200-3%203c0%202%200%202%203%202s3%200%203%204v3h-8c-5%200-8%200-7%201%202%201-5%206-8%206-7%200-7%200-7%206%200%205-1%206-3%206-3%200-4-1-4-4s0-3-5-2l-4-1h-2l-1-1c1-1%200-1-1-2-2%200-3-2-3-3l-3-2h-3c-1-1-3-2-4-1l-2-1-3-2-1-1-9-2-2-2-4-1h-4l-4-1-14-3-5-1c-2%201-3%201-4-1l-2-1h-10l-2%202-3%201-2%202-3%201-1%201c1%203-5%202-7-1-2-4-4-15-3-16l11-1c13-1%2018-3%207-3l-9-1h-3l-3-2-1-1-1-2c-1-1-1-1%201-2%205-2-93-1-139%202H0v11h7l73-1-2%2010-2%209H48c-22%201-29%200-34-1-7-1-7-1-9%201l-3%202c-2%200-2%201-2%2015v16l4%201c12%203%2030%206%2033%205h4l-5-1c-5-1-4-3%201-3h4l-4-2-3-2%208%201%2015%201%2015%202c6%200%209%201%2010%202l-18%201H46l17%201c18%200%2019%200%2019%204%200%201-3%202-21%201H40l5%205%2010%209%205%204-13-8c-2-2-11-6-16-6a1264%201264%200%2000-17-3l-4-1-6-2H0v104h321V94l-1-90V0h-6c-6%200-7%200-9%203M81%2017l-2%2010-2%207h4l6-1c1-2%204-2%2011-2l10-1%2017-1%2016-1c0-2-4-3-7-3-5%200-13%200-11-1%202%200%202-1%202-5%200-2%200-4-1-3l-1-1-20-1H82l-1%203m219%209v6h3c3%200%203%200%203%203-1%202-1%202%205%202s6%200%206-2c0-3%200-3-3-3s-3%200-3-3%200-3-3-3c-2%200-3%200-3-3%200-2%200-3-2-3-3%200-3%200-3%206m-57%208l-1%203%209%201h10v-6h-9c-8%200-9%200-9%202M123%2050v9l1%207h7l8-1V48h-8c-6%200-7%200-8%202m22-1c-2%200-2%204-1%2013l1%205%205-1%207-1h3v-8l-1-8h-14m-41%201l-2%201-1%203%202%208v5h15V52l-5-1-5-1h-4m26%2021h-4l-2%201c-1%200-1%2014%201%2015h15v-6l-1-8-3-1c-3%200-4-1-5-2s-1-1-1%201m-26%200l-2%202-1%203v3l2%205c1%205%202%206%2011%205%206-1%206-2%204-12v-5h-5l-4-1h-5m42%200c-2%200-2%201-2%205l1%209v3h15V71h-14m-20%209v5h5c6%200%207-2%206-8-1-4-5-4-5%200v4l-1-4c-2-6-5-4-5%203m1%2011l-1%201c-2%201-2%202-2%207%200%207%200%208%208%208%208%201%208%201%207-8v-6h-4l-5-2-2-1-1%201m20%200l-2%201-1%208%201%208%208-1h7V93l-5-1-5-1-1-1-2%201m-40%201c-2%202-2%206-1%2012v4h15v-4c0-8-1-11-3-11-6-2-10-2-11-1m68%2013c-6%202-10%205-9%208l-1%202h-1l1%202%201-1%202%201%203%202-1-2v-1c1%201%203%200%205-1l5-1%204%201%2010-2%201-3%201-4c0-2-12-2-21-1m109%2028l-6%202c-2%201%200%206%202%207%203%202%2015%205%2015%204%201-1-4-14-5-14l-6%201'%20fill='%23d3d3d3'%20fill-rule='evenodd'/%3e%3c/svg%3e","aspectRatio":1.7777777777777777,"src":"/static/33e3d595276bd9d1a8c431dbe54202e2/a213b/preview.png","srcSet":"/static/33e3d595276bd9d1a8c431dbe54202e2/d0c86/preview.png 80w,\n/static/33e3d595276bd9d1a8c431dbe54202e2/c07f7/preview.png 160w,\n/static/33e3d595276bd9d1a8c431dbe54202e2/a213b/preview.png 320w,\n/static/33e3d595276bd9d1a8c431dbe54202e2/0f64e/preview.png 480w,\n/static/33e3d595276bd9d1a8c431dbe54202e2/2eb90/preview.png 640w,\n/static/33e3d595276bd9d1a8c431dbe54202e2/de924/preview.png 1724w","sizes":"(max-width: 320px) 100vw, 320px"}}},"date":"May 2022 - Present","venue":"","authors":[],"path":"research/mmtutor","title":"Multimodal Cognitive Tutor","tags":["IntelligentTutoringSystem","XR","HCI"],"excerpt":"A new ITS framework generalizable for 3D physical task learning. By leveraging AI and AR methods, it can not only generate adaptive guidance by modeling users’ learning stage and measuring difficulties of learning objects through multimodal input, but also preserve perspectives of reality for users with spatially augmented animations that reduce users’ cognitive load.","selected":true,"priority":1,"links":[{"name":"poster","url":"poster.pdf"},{"name":"Github","url":"https://github.com/HumanAILab/Multimodal-Tutor"}]},"fileAbsolutePath":"/home/runner/work/henrw.github.io/henrw.github.io/content/research/mmtutor/index.md"}},{"node":{"frontmatter":{"cover":{"childImageSharp":{"fluid":{"tracedSVG":"data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20width='320'%20height='180'%20viewBox='0%200%20320%20180'%20preserveAspectRatio='none'%3e%3cpath%20d='M310%2023c-2%202-4%205-6%205l-2%202c0%202-5%207-7%206l-1%202c-1%203-3%201-3-3%200-10-4-15-10-11-4%203-7%204-16%206-16%202-18%203-19%209a142%20142%200%2001-14%2049c0%203-11%208-17%208h-2l2%201%208%201c7-1%206-1%208%209v5h13l12-1c0-2-2-2-8-2s-8%200-8-2c-2-3-1-3%205-3l8-1-6-1c-7%200-9-1-9-3l7-1c8%200%209-2%201-3-11%200-11%200-8-1l2-2c-1-2%207-10%209-10s3%202%200%205c-2%204-1%205%206%205%208%201%207%200%2011%2013%203%2011%203%2012%202%2020l-6%2034-24%201c-21%200-25%201-27%202s-7%203-11%203c-10%202-13%204-8%206%207%201%2096-1%20100-2%205-2%205-2%202-8l-5-6-3-2-2-1-2-2c0-1%206-8%208-8a169%20169%200%200027-28l3-3V67c0-41-1-44-2-46-3-3-5-2-8%202M195%2096c-3%200-6%202-8%203-4%204-5%204-5%200%200-3%200-3-4-3h-4v4l1%208v5h4c4%200%204%200%204-3%200-4%202-5%208-1%203%203%205%204%209%204h4l-6-5c-7-5-7-6-2-9l4-3v-1l-5%201m-9%2029c-13%204-19%2021-8%2028%204%203%2010%204%2017%203%204%200%205-1%204-3%200-3%200-3-5-3-9%200-12-2-12-9s6-12%2015-11c4%201%204%201%205-1%202-5-7-7-16-4m43%202c-1%203-1%203%204%203l5%201-1%208c-1%2017-1%2017%203%2018%204%200%204%200%205-14l2-12%204-1c5%200%206-1%206-4%200-2-1-2-14-2h-14v3m-67%2016l1%2019h4l12-2h-2l-1-1v-1l-5-10-2-4-3-9-1-3-1-2-1-4c-1-1-1%205-1%2017m-93%206v18h8v-7l1-7%206-1c5%200%206%200%206-3v-3H78l-1-4v-4h14v-7H69v18m58-12l-8%2027c0%203%200%203%204%203s4%200%205-4l1-5h11l1%205c1%204%201%204%206%204%204%200%204%200%203-2l-9-29-1-5h-11l-2%206'%20fill='%23d3d3d3'%20fill-rule='evenodd'/%3e%3c/svg%3e","aspectRatio":1.7777777777777777,"src":"/static/ce3eaa6a10de6ef1d25156d1e874a972/50d6c/preview.jpg","srcSet":"/static/ce3eaa6a10de6ef1d25156d1e874a972/c79db/preview.jpg 80w,\n/static/ce3eaa6a10de6ef1d25156d1e874a972/0a386/preview.jpg 160w,\n/static/ce3eaa6a10de6ef1d25156d1e874a972/50d6c/preview.jpg 320w,\n/static/ce3eaa6a10de6ef1d25156d1e874a972/5442a/preview.jpg 480w,\n/static/ce3eaa6a10de6ef1d25156d1e874a972/1c7b6/preview.jpg 500w","sizes":"(max-width: 320px) 100vw, 320px"}}},"date":"Jul 2022 - Present","venue":"","authors":[],"path":"research/misinfoengage","title":"Towards Understanding the Relation between Misinformation and Engagement","tags":["MisinformationDetection","MultimodalLearning","NLP"],"excerpt":"Create an interpretable video engagement rating pipeline consisting of multimodal data preprocessing, feature extraction with time alignment, and a special early fusion model; analyze the relation between misinformation and engagement.","selected":true,"priority":2,"links":[{"name":"Github","url":"https://github.com/henrw/Misinfo-Engagement"}]},"fileAbsolutePath":"/home/runner/work/henrw.github.io/henrw.github.io/content/research/misinfoengage/index.md"}},{"node":{"frontmatter":{"cover":{"childImageSharp":{"fluid":{"tracedSVG":"data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20width='320'%20height='180'%20viewBox='0%200%20320%20180'%20preserveAspectRatio='none'%3e%3cpath%20d='M0%2016v17h3l1%202-2%201c-2-1-2%200-2%209s0%209%202%208%204-3%204-5l1-3%201%202c0%201%201%201%203-2%203-2%205-3%206-2v-4c3%200%202-2-2-4-3-1-7-4-7-6l-3-1c-2%200-3%200-2-1%201-2%209-1%2018%203%205%203%209%203%207%201l-2-2c-2%200-7-4-6-5s0-1-1-1h-1v-1c-3-2-2-3%202-3%203%200%204%200%204-2s0-2%203-1h2l-2-2c-5-4-3-4%206%200l11%205%204%201h1v-1l-1-1%202-1c3%201%205-1%205-3l1-2-1-3-2-2-2-3c-4-2-4-3%203-3%206%200%207%200%209%203l5%202%205%202a125%20125%200%20005%204h2c-1-2%200-2%204-2l4-1%208-1%208-1c0-2%201-2%204-2s4%200%204-2c0-1%2023-1%2024%201l1-2V0H0v16M198%201l2%203h8c0%202%204%204%205%202l3-1c1%201%203%200%205-1%203-3%205-3%2016-3%209-1%208-1-4-1l-17%201h-2l-9-1c-7%200-8%200-7%201m62%201l5%201c1-1%202%200%204%202%202%204%202%205-2%205s-5%202-3%204v2l-2%201c1%201%205%200%2011-3%204-2%205-3%203-5l1-1h4l5%202c2%200%203%200%202%202l-1%201-3%202-5%201c-2%200-3%201-3%203v5c-1%204%201%205%208%205%206%200%206%201%206%203s5%207%206%205c0-3%204-1%205%203l2%203c1-1%203%200%206%202%202%203%203%203%203%202l1-2%202%203c0%202%201%204%203%205s2%201%202-26V0h-31c-27%200-30%200-29%202M140%2052l-1%2020%201%2017h-6c-5%200-5%200-4%202%202%201%2010%202%2012%200s1-40%200-42c-2-1-2-1-2%203m81%200v4h-12v4c0%204%200%204%203%204l2-2c0-2%201-2%205-2%205%200%205%200%206-5%201-2%201-3-1-5l-2-2-1%204m-28%2017v20h-5c-7%200-6%202%201%203l6-1c2-3%201-42%200-42-2%200-2%203-2%2020m-37%201v19h-5c-7%200-6%202%200%203%208%200%208%200%208-22l-1-20c-2%200-2%203-2%2020m-45%208v11h-5c-5%200-6%201-4%203%202%201%209%200%2011-1l1-10-1-13c-2%200-2%202-2%2010M53%2094H0v86h321v-44c0-40%200-43-2-42a1343%201343%200%2001-62%202c1%201%202%202%201%203%200%202-2%203-2%201l-2%201-5%203-4%201-2-1c-4-4-4-2-5%2014%200%2015%200%2016-2%2017l-2%202c-1%203-29%203-29%200l-2-2c-2%200-2-1-2-7%200-18-1-27-2-28s-2%203-2%2019v20h-33v-9l1-9v-3l-1-7c0-4-1-8-3-8l-1%2016c0%2015%200%2016-2%2016l-2%202c0%202-1%202-14%202-14%200-15%200-15-2l-2-2c-2%200-2-1-2-13s-1-14-2-14c-2%200-2%201-2%2011v12h-3c-4%200-5%200-5%202l-2%202-2%202c-1%202-2%202-13%202H82v-13l-1-14c-3%201-6%200-5-1%202-2%201-3-3-4l-4-2-3-1-3-1v-1l1-1c0-1-1-2-2-1l-1-1c1-1%203-2%209-2%2012%200%2013-2%201-2l-11-1c-1-2-6-2-7%200m42%2014c-1%2021-1%2022%206%2022h5v-8c0-5%200-8-1-7-1%202-4%202-5%200-1-3%200-4%203-4s3%200%203-2c0-3%200-3-5-3s-6%200-6%202m41-1l-1%2012%201%2011h11v-5c0-4%200-4-1-2l-1%201h-1c-2%200-4-4-4-9%200-4%202-6%205-5%202%200%202%200%202-2s-1-2-5-2l-6%201m78%200l-1%2012v11h12v-24h-5l-6%201'%20fill='%23d3d3d3'%20fill-rule='evenodd'/%3e%3c/svg%3e","aspectRatio":1.7777777777777777,"src":"/static/36774acd34ad4f622641522bc9e8d1c8/50d6c/preview.jpg","srcSet":"/static/36774acd34ad4f622641522bc9e8d1c8/c79db/preview.jpg 80w,\n/static/36774acd34ad4f622641522bc9e8d1c8/0a386/preview.jpg 160w,\n/static/36774acd34ad4f622641522bc9e8d1c8/50d6c/preview.jpg 320w,\n/static/36774acd34ad4f622641522bc9e8d1c8/5442a/preview.jpg 480w,\n/static/36774acd34ad4f622641522bc9e8d1c8/ff9da/preview.jpg 640w,\n/static/36774acd34ad4f622641522bc9e8d1c8/b51b8/preview.jpg 800w","sizes":"(max-width: 320px) 100vw, 320px"}}},"date":"Jul 2022 - Oct 2022","venue":"","authors":[],"path":"research/minedojo","title":"MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge","tags":["GeneralistAgent","Simulation","RL"],"excerpt":"Investigate EGL docker image to enable GPU acceleration for scalable MineDojo RL simulation on headless machines; construct a meta-dataset of 20 open-ended, task-oriented datasets as the knowledge base for generalist agent training.","selected":true,"priority":10,"links":[{"name":"website","url":"https://minedojo.org/"}]},"fileAbsolutePath":"/home/runner/work/henrw.github.io/henrw.github.io/content/research/minedojo/index.md"}}]}}}